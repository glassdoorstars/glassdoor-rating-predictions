{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab91ddd-f4e7-4d61-91f8-0661e1b97539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to install pip webdriver manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19bfd236-bc3b-453f-a749-148edf06a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "for step in range(100, 103):\n",
    "    data = []\n",
    "\n",
    "    for page_number in range(1):\n",
    "\n",
    "        url = f\"https://www.glassdoor.com/Reviews/index.htm?overall_rating_low=1&page={step}&locId=1&locType=N&locName=United%20States&filterType=RATING_OVERALL\"\n",
    "        # access company page\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service = service)\n",
    "        driver.get(url)\n",
    "        review_links = driver.find_elements(By.XPATH, '//span[@class=\"css-u9lko5 euttuq60\"]')\n",
    "        # Find employer name tags\n",
    "        # Find employer rating tags\n",
    "\n",
    "\n",
    "        review_urls = []\n",
    "        for ele in driver.find_elements(By.XPATH, '//a[@data-test=\"cell-Reviews-url\"]'):\n",
    "            review_urls.append(ele.get_attribute(\"href\"))\n",
    "        # Create a list to store data\n",
    "\n",
    "        # Initialize webdriver service\n",
    "        # Loop through company URLs\n",
    "        for i, review_url in enumerate(review_urls):\n",
    "            company_data = {'url': review_url,\n",
    "                            'pros': '',\n",
    "                            'cons': ''}\n",
    "            for i in range(10):\n",
    "                driver = webdriver.Chrome(service=service)\n",
    "                driver.get(review_url)\n",
    "                # Extract pros and cons\n",
    "                pros = [pro.text for pro in driver.find_elements(By.XPATH, \"//span[@data-test='pros']\")]\n",
    "                cons = [con.text for con in driver.find_elements(By.XPATH, \"//span[@data-test='cons']\")]\n",
    "                # Add to company_data\n",
    "                company_data['pros'] += ' '.join(pros)\n",
    "                company_data['cons'] += ' '.join(cons)\n",
    "                try:\n",
    "                    # Try to click the pagination next button\n",
    "                    pagination_next = driver.find_element(By.XPATH, '//button[@data-test=\"pagination-next\"]')\n",
    "                    pagination_next.click()\n",
    "                    next_url = driver.current_url\n",
    "                except:\n",
    "                    # If there's no next page, break the loop\n",
    "                    print('error')\n",
    "                    break\n",
    "                driver.quit()\n",
    "            data.append(company_data)\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame(data)\n",
    "    csv_filename = f'./part3/victoire_part3_{step}.csv'  # Change this to your desired filename\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(step)\n",
    "    time.sleep(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0f911ba-582c-40de-bc3d-b0f4abdb0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# data_frames = []\n",
    "# files = pd.Series(os.listdir(\"./part3\"))\n",
    "# files = files[~files.isin([\".DS_Store\", \".ipynb_checkpoints\"])]\n",
    "\n",
    "# for file in files.values:\n",
    "#     file_path = os.path.join(\"./part3\", file)\n",
    "#     # if file.endswith(\".csv\"):\n",
    "#     df = pd.read_csv(file_path)\n",
    "#     data_frames.append(df)\n",
    "# combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "# combined_df.to_csv(\"glassdoor_part3.csv\")\n",
    "# # combined_df.to_csv(\"../glassdoor_part3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1bb4a6-6ae1-41cb-b652-9f82d6ab0385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "data_frames = []\n",
    "data_folder = os.listdir(\"./data_folder\")\n",
    "\n",
    "for folder in data_folder:\n",
    "    folder_path = os.path.join('./data_folder', folder)\n",
    "    parts = [\".DS_Store\", \".ipynb_checkpoints\"]\n",
    "    if folder not in parts:\n",
    "        files = pd.Series(os.listdir(folder_path))\n",
    "        for ele in files:\n",
    "            if ele.endswith(\".csv\"):\n",
    "                df = pd.read_csv(f\"./data_folder/{folder}/{ele}\")\n",
    "                data_frames.append(df)\n",
    "        \n",
    "combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "combined_df.to_csv(\"glassdoor_full.csv\", mode= \"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
