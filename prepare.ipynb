{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5004ddeb-e5ce-4a52-ace9-4ffe0ee0183f",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b321ed32-b5a6-45ad-b341-80679e381954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# natural language processing\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Quiet all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845303b3-d479-4e24-80b5-0bd4ccaccd8d",
   "metadata": {},
   "source": [
    "**Get data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "689faf18-8eb0-434e-85c9-db179737fc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.glassdoor.com/Reviews/Memorial-Her...</td>\n",
       "      <td>Great coworkers Wonderful Work environment Tho...</td>\n",
       "      <td>Overall, I love working at this hospital. Ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.glassdoor.com/Reviews/Chicago-Publ...</td>\n",
       "      <td>Great pay and benefits including union support...</td>\n",
       "      <td>Heavy work load, long hours. Huge Class Sizes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.glassdoor.com/Reviews/Gensler-Revi...</td>\n",
       "      <td>Even though it's the largest firm in the world...</td>\n",
       "      <td>No cons but I have to type something in this b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.glassdoor.com/Reviews/Inova-Review...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.glassdoor.com/Reviews/Five-Guys-Bu...</td>\n",
       "      <td>Great benefits , get incentives and growth wit...</td>\n",
       "      <td>It takes a while to receive raises and promoti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.glassdoor.com/Reviews/Memorial-Her...   \n",
       "1  https://www.glassdoor.com/Reviews/Chicago-Publ...   \n",
       "2  https://www.glassdoor.com/Reviews/Gensler-Revi...   \n",
       "3  https://www.glassdoor.com/Reviews/Inova-Review...   \n",
       "4  https://www.glassdoor.com/Reviews/Five-Guys-Bu...   \n",
       "\n",
       "                                                pros  \\\n",
       "0  Great coworkers Wonderful Work environment Tho...   \n",
       "1  Great pay and benefits including union support...   \n",
       "2  Even though it's the largest firm in the world...   \n",
       "3                                                NaN   \n",
       "4  Great benefits , get incentives and growth wit...   \n",
       "\n",
       "                                                cons  \n",
       "0  Overall, I love working at this hospital. Ther...  \n",
       "1  Heavy work load, long hours. Huge Class Sizes ...  \n",
       "2  No cons but I have to type something in this b...  \n",
       "3                                                NaN  \n",
       "4  It takes a while to receive raises and promoti...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glassdrs = wrangle.combine_all_files()\n",
    "glassdrs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ad6395-e09b-483b-be2b-e1af216d1b1f",
   "metadata": {},
   "source": [
    "**Remove any row with with nulls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34aacc17-33c4-4349-9ff6-aabee780eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any nuls found in the pros and cons section of the data\n",
    "glassdrs = glassdrs.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "844067de-4971-491a-b3b2-933302ed1a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glassdrs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6c036-7d08-46b6-9828-4aee6c8e96fc",
   "metadata": {},
   "source": [
    "**Bin rating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf84ffe-f90c-417a-905f-051509fad542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define bin edges\n",
    "# bin_edges = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "\n",
    "# # Define bin labels\n",
    "# bin_labels = ['One', 'Two', 'Three', 'Four']\n",
    "\n",
    "# # Bin the 'rating' column\n",
    "# glassdrs['binned_rating'] = pd.cut(glassdrs['rating'], bins=bin_edges, labels=bin_labels, right=False)\n",
    "# glassdrs.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8c4765-5839-4510-be86-a873e2b6f5b0",
   "metadata": {},
   "source": [
    "**Clean strings**\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d01e12d-70ae-40f1-8c31-a8281d4f0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    \"\"\"\n",
    "    This function puts a string in lowercase, normalizes any unicode characters, removes anything that         \n",
    "    isn't an alphanumeric symbol or single quote.\n",
    "    \"\"\"\n",
    "    # Normalize unicode characters\n",
    "    string = unicodedata.normalize('NFKD', string).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    \n",
    "    # Remove unwanted characters and put string in lowercase\n",
    "    string = re.sub(r\"[^\\w0-9'\\s]\", '', string).lower()\n",
    "            \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030cd05b-8b19-4584-83dc-932ced100e2f",
   "metadata": {},
   "source": [
    "**Lemmatize**\n",
    "- Apply lemmatization to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f38d959-c07b-40b8-9573-666da964a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    \"\"\"\n",
    "    This function takes in a string, lemmatizes each word, and returns a lemmatized version of the orignal string\n",
    "    \"\"\"\n",
    "    # Build the lemmatizer\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # Run the lemmatizer on each word after splitting the input string, store results in the 'results' list\n",
    "    results = []\n",
    "    for word in string.split():\n",
    "        results.append(lemmatizer.lemmatize(word))\n",
    "    \n",
    "    # Convert results back into a string\n",
    "    string = ' '.join(results)\n",
    "    \n",
    "    # Return the resulting string\n",
    "    return string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1776f85-9f31-4126-805d-a3dc6a6c1045",
   "metadata": {},
   "source": [
    "**Remove stop words**\n",
    "- Remove all stop words from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d556471-5ad1-4957-9536-6efd2fa5dc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words=None, exclude_words=None):\n",
    "    \"\"\"\n",
    "    Takes in a string, with optional arguments for words to add to stock stopwords and words to ignore in the \n",
    "    stock list removes the stopwords, and returns a stopword free version of the original string\n",
    "    \"\"\"\n",
    "    # Get the list of stopwords from nltk\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Create a set of stopwords to exclude\n",
    "    excluded_stopwords = set(exclude_words) if exclude_words else set()\n",
    "    \n",
    "    # Include any extra words in the stopwords to exclude\n",
    "    stopwords_to_exclude = set(stopword_list) - excluded_stopwords\n",
    "    \n",
    "    # Add extra words to the stopwords set\n",
    "    stopwords_to_exclude |= set(extra_words) if extra_words else set()\n",
    "    \n",
    "    # Tokenize the input string\n",
    "    words = string.split()\n",
    "    \n",
    "    # Filter out stopwords from the tokenized words\n",
    "    filtered_words = [word for word in words if word not in stopwords_to_exclude]\n",
    "    \n",
    "    # Convert back to string\n",
    "    string = ' '.join(filtered_words)\n",
    "    \n",
    "    # Return the resulting string\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32f6589-9dc7-4519-b8f3-51b29ba626d4",
   "metadata": {},
   "source": [
    "**Split data**\n",
    "- Apply a 60% training, 20% Validation, and 20% testing split to the data. (Random state 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2bf6ea6-6c50-427f-bf00-fa2b3e39d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_readmes(df):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe and performs a 70/15/15 split. Outputs a train, validate, and test dataframe\n",
    "    \"\"\"\n",
    "    # Perfrom a 70/15/15 split\n",
    "    train_val, test = train_test_split(df, test_size=.2, random_state=95)\n",
    "    train, validate = train_test_split(train_val, test_size=.25, random_state=95)\n",
    "    \n",
    "    # Return the dataframe slices\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aede4b95-c6c8-4b37-93a7-f984f324c457",
   "metadata": {},
   "source": [
    "**Prepare data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a96995dd-b58f-4e3e-9568-d1017e8afe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_readmes(df, cols:str=[]):\n",
    "    \"\"\"\n",
    "    Takes in the dataframe and the column name that contains the corpus data, creates a column of cleaned data, then uses that \n",
    "    to create a column without stopwords that is lemmatized, performs a train-validate-test split, and returns train, validate,\n",
    "    and test.\n",
    "    \"\"\"\n",
    "    for idx, col in enumerate(cols):\n",
    "        # Initialize a list to collect cleaned elements in the for-loop below\n",
    "        cleaned_row = []\n",
    "\n",
    "        # Iterate through the readme_content values...\n",
    "        for i in df[col].values:\n",
    "\n",
    "            # Clean each value in the column and append to the 'cleaned_row' list\n",
    "            cleaned_row.append(clean(i))\n",
    "        \n",
    "        if idx == 0:\n",
    "            # Assign the clean row content to a new column in the dataframe named 'cleaned_content\n",
    "            df = df.assign(pros_cleaned_content=cleaned_row)\n",
    "            \n",
    "            # Using a lambda, lemmatize all values in the 'cleaned_content' column and assign to a new column called 'lemmatized'\n",
    "            df[f'{col}_lemmatized'] = df['pros_cleaned_content'].apply(lambda x: lemmatize(remove_stopwords(x)))\n",
    "        if idx == 1:\n",
    "            # Assign the clean row content to a new column in the dataframe named 'cleaned_content\n",
    "            df = df.assign(cons_cleaned_content=cleaned_row)\n",
    "            # Using a lambda, lemmatize all values in the 'cleaned_content' column and assign to a new column called 'lemmatized'\n",
    "            df[f'{col}_lemmatized'] = df['cons_cleaned_content'].apply(lambda x: lemmatize(remove_stopwords(x)))\n",
    "\n",
    "    # Split the dataframe (70/15/15)\n",
    "    train, validate, test = split_readmes(df)\n",
    "    \n",
    "    # Return train, validate, and test dataframes\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "635e3d9a-c9b5-4343-8e8a-bf1cd09005dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = prep_readmes(glassdrs, [\"pros\", \"cons\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a586efa-0866-4d7e-bc08-4eeb891e6ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((613, 7), (205, 7), (205, 7))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5a9498c-f335-48c8-832c-231b1df46a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>pros_cleaned_content</th>\n",
       "      <th>pros_lemmatized</th>\n",
       "      <th>cons_cleaned_content</th>\n",
       "      <th>cons_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>https://www.glassdoor.com/Reviews/Medline-Indu...</td>\n",
       "      <td>Flexible schedule, fast paced, independent wor...</td>\n",
       "      <td>Departments can be siloed, e-commerce could us...</td>\n",
       "      <td>flexible schedule fast paced independent work ...</td>\n",
       "      <td>flexible schedule fast paced independent work ...</td>\n",
       "      <td>departments can be siloed ecommerce could use ...</td>\n",
       "      <td>department siloed ecommerce could use improvem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>https://www.glassdoor.com/Reviews/OfficeMax-Re...</td>\n",
       "      <td>Supportive management, community involvement, ...</td>\n",
       "      <td>Can be hard to move up No cons that i can thin...</td>\n",
       "      <td>supportive management community involvement ge...</td>\n",
       "      <td>supportive management community involvement ge...</td>\n",
       "      <td>can be hard to move up no cons that i can thin...</td>\n",
       "      <td>hard move con think living wage sofl pay lacki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>https://www.glassdoor.com/Reviews/Pier-1-Impor...</td>\n",
       "      <td>Solid place to work at Pier one was a great st...</td>\n",
       "      <td>No complaints great company and management I’m...</td>\n",
       "      <td>solid place to work at pier one was a great st...</td>\n",
       "      <td>solid place work pier one great store work exc...</td>\n",
       "      <td>no complaints great company and management im ...</td>\n",
       "      <td>complaint great company management im sorry st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>https://www.glassdoor.com/Reviews/UScellular-R...</td>\n",
       "      <td>Genuine people and culture, fair pay and benef...</td>\n",
       "      <td>No major cons come to mind Tough to have work ...</td>\n",
       "      <td>genuine people and culture fair pay and benefi...</td>\n",
       "      <td>genuine people culture fair pay benefit proact...</td>\n",
       "      <td>no major cons come to mind tough to have work ...</td>\n",
       "      <td>major con come mind tough work life balance u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>https://www.glassdoor.com/Reviews/Discount-Tir...</td>\n",
       "      <td>Decent pay, great management, very well mainta...</td>\n",
       "      <td>Facial hair is not allowed. Must be clean shav...</td>\n",
       "      <td>decent pay great management very well maintain...</td>\n",
       "      <td>decent pay great management well maintained eq...</td>\n",
       "      <td>facial hair is not allowed must be clean shave...</td>\n",
       "      <td>facial hair allowed must clean shaven manageme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "556  https://www.glassdoor.com/Reviews/Medline-Indu...   \n",
       "946  https://www.glassdoor.com/Reviews/OfficeMax-Re...   \n",
       "361  https://www.glassdoor.com/Reviews/Pier-1-Impor...   \n",
       "238  https://www.glassdoor.com/Reviews/UScellular-R...   \n",
       "893  https://www.glassdoor.com/Reviews/Discount-Tir...   \n",
       "\n",
       "                                                  pros  \\\n",
       "556  Flexible schedule, fast paced, independent wor...   \n",
       "946  Supportive management, community involvement, ...   \n",
       "361  Solid place to work at Pier one was a great st...   \n",
       "238  Genuine people and culture, fair pay and benef...   \n",
       "893  Decent pay, great management, very well mainta...   \n",
       "\n",
       "                                                  cons  \\\n",
       "556  Departments can be siloed, e-commerce could us...   \n",
       "946  Can be hard to move up No cons that i can thin...   \n",
       "361  No complaints great company and management I’m...   \n",
       "238  No major cons come to mind Tough to have work ...   \n",
       "893  Facial hair is not allowed. Must be clean shav...   \n",
       "\n",
       "                                  pros_cleaned_content  \\\n",
       "556  flexible schedule fast paced independent work ...   \n",
       "946  supportive management community involvement ge...   \n",
       "361  solid place to work at pier one was a great st...   \n",
       "238  genuine people and culture fair pay and benefi...   \n",
       "893  decent pay great management very well maintain...   \n",
       "\n",
       "                                       pros_lemmatized  \\\n",
       "556  flexible schedule fast paced independent work ...   \n",
       "946  supportive management community involvement ge...   \n",
       "361  solid place work pier one great store work exc...   \n",
       "238  genuine people culture fair pay benefit proact...   \n",
       "893  decent pay great management well maintained eq...   \n",
       "\n",
       "                                  cons_cleaned_content  \\\n",
       "556  departments can be siloed ecommerce could use ...   \n",
       "946  can be hard to move up no cons that i can thin...   \n",
       "361  no complaints great company and management im ...   \n",
       "238  no major cons come to mind tough to have work ...   \n",
       "893  facial hair is not allowed must be clean shave...   \n",
       "\n",
       "                                       cons_lemmatized  \n",
       "556  department siloed ecommerce could use improvem...  \n",
       "946  hard move con think living wage sofl pay lacki...  \n",
       "361  complaint great company management im sorry st...  \n",
       "238  major con come mind tough work life balance u ...  \n",
       "893  facial hair allowed must clean shaven manageme...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf17da-fd55-4a42-9b8c-6d0f0da93715",
   "metadata": {},
   "source": [
    "## Preparation actions taken\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "- Lemmatize\n",
    "- Remove stop words\n",
    "- 60, 20, 20 split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
